{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0a6c50-5935-4735-a75f-8ba1be34dcb9",
   "metadata": {},
   "source": [
    "## Basic examples with PlantCaduceus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276c2d7-af5a-46b8-9dec-a49ac3fec114",
   "metadata": {},
   "source": [
    "### Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def1ceb4-8c76-4900-81c9-97f7737e19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet mamba-ssm==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f38be32-0038-4772-8188-797d26a485a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967fa148-f338-4bfa-9a90-57babfe4ed4e",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365607a1-562e-4d2c-b1ca-313a45703165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaduceusForMaskedLM(\n",
       "  (caduceus): Caduceus(\n",
       "    (backbone): CaduceusMixerModel(\n",
       "      (embeddings): CaduceusEmbeddings(\n",
       "        (word_embeddings): RCPSEmbedding(\n",
       "          (embedding): Embedding(8, 384)\n",
       "        )\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-19): 20 x RCPSMambaBlock(\n",
       "          (mixer): RCPSWrapper(\n",
       "            (submodule): BiMambaWrapper(\n",
       "              (mamba_fwd): Mamba(\n",
       "                (in_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "                (conv1d): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(3,), groups=768)\n",
       "                (act): SiLU()\n",
       "                (x_proj): Linear(in_features=768, out_features=56, bias=False)\n",
       "                (dt_proj): Linear(in_features=24, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=384, bias=False)\n",
       "              )\n",
       "              (mamba_rev): Mamba(\n",
       "                (in_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "                (conv1d): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(3,), groups=768)\n",
       "                (act): SiLU()\n",
       "                (x_proj): Linear(in_features=768, out_features=56, bias=False)\n",
       "                (dt_proj): Linear(in_features=24, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=384, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RCPSLMHead(\n",
       "    (lm_head): Linear(in_features=384, out_features=8, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'kuleshov-group/PlantCaduceus_l20'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path, trust_remote_code=True, device_map=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21caf701-999f-4834-b142-f8d893e52a33",
   "metadata": {},
   "source": [
    "### Tokenize the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d2ea31-2c9f-48f1-83b3-19e45a7c841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "sequence = \"CTTAATTAATATTGCCTTTGTAATAACGCGCGAAACACAAATCTTCTCTGCCTAATGCAGTAGTCATGTGTTGACTCCTTCAAAATTTCCAAGAAGTTAGTGGCTGGTGTGTCATTGTCTTCATCTTTTTTTTTTTTTTTTTAAAAATTGAATGCGACATGTACTCCTCAACGTATAAGCTCAATGCTTGTTACTGAAACATCTCTTGTCTGATTTTTTCAGGCTAAGTCTTACAGAAAGTGATTGGGCACTTCAATGGCTTTCACAAATGAAAAAGATGGATCTAAGGGATTTGTGAAGAGAGTGGCTTCATCTTTCTCCATGAGGAAGAAGAAGAATGCAACAAGTGAACCCAAGTTGCTTCCAAGATCGAAATCAACAGGTTCTGCTAACTTTGAATCCATGAGGCTACCTGCAACGAAGAAGATTTCAGATGTCACAAACAAAACAAGGATCAAACCATTAGGTGGTGTAGCACCAGCACAACCAAGAAGGGAAAAGATCGATGATCG\"\n",
    "encoding = tokenizer.encode_plus(\n",
    "            sequence,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=False,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "input_ids = encoding[\"input_ids\"].to(device)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf43ae-53f3-4cc1-b319-04205a19e4d2",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825f04d1-8026-4926-b789-bb1d32396584",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs = model(input_ids=input_ids, output_hidden_states=True)\n",
    "emeddings = outputs.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ada5d10-85c9-47ad-8a90-12e62f2e42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "print(emeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b32ab-cfc6-4a4f-b6c1-e6f007bd2292",
   "metadata": {},
   "source": [
    "#### Averaging forward and reverse embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d395ff9-9ddf-4602-9100-c0dfd860d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "emeddings = emeddings.to(torch.float32).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34eebe0a-d687-45fc-bdd1-bd4b7850a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 384)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = emeddings.shape[-1] // 2\n",
    "forward = emeddings[..., 0:hidden_size]\n",
    "reverse = emeddings[..., hidden_size:]\n",
    "reverse = reverse[..., ::-1]\n",
    "averaged_embeddings = (forward + reverse) / 2\n",
    "print(averaged_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac65c4f-0a97-4631-a228-edbb82b5c709",
   "metadata": {},
   "source": [
    "### Masked token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6f3a9f-4907-4dcf-98a9-5fd6ea2cd63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 255\n",
    "sequence[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe0f831-6583-4d11-862d-4b552f595bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0, pos] = tokenizer.mask_token_id\n",
    "with torch.inference_mode():\n",
    "    outputs = model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474f1635-30e3-4198-b882-b02ca4e9efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = list('acgt')\n",
    "logits = outputs.logits\n",
    "logits = logits[:, pos, [tokenizer.get_vocab()[nc] for nc in nucleotides]]\n",
    "probs = torch.nn.functional.softmax(logits.cpu(), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80c8ffb-b0b5-433f-a36d-cda90ddbb2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96960527, 0.00782286, 0.01123959, 0.01133224]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df0609b-10f1-4dde-97f7-0cdcb41c00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(nucleotides = nucleotides, probs = probs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "906780da-6eef-4385-bc81-1a02735e751d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.969605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g</td>\n",
       "      <td>0.011240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>0.011332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleotides     probs\n",
       "0           a  0.969605\n",
       "1           c  0.007823\n",
       "2           g  0.011240\n",
       "3           t  0.011332"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
